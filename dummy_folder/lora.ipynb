{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ee4c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install torch --index-url https://download.pytorch.org/whl/cu118  # CUDA 11.8 기준\n",
    "# !pip install transformers datasets peft bitsandbytes huggingface_hub python-dotenv chromadb\n",
    "# !pip install einops timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "513969b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training, PeftModel\n",
    "from datasets import load_dataset\n",
    "import chromadb\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bacb6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "login(token=os.getenv('HF_TOKEN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4c6d577",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d23bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a10f94e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4027b62ef31d4572bbb13b095873c2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "image_processing_hyperclovax.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Vision-Instruct-3B:\n",
      "- image_processing_hyperclovax.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/naver-hyperclovax/HyperCLOVAX-SEED-Vision-Instruct-3B:\n",
      "- image_processing_hyperclovax.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1889b41ea642a1a00ae2f3d9f38719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "190ae5e45afa4611b410a5f1a356570f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d1149b3b314e32a02f147e1e359e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851da42d885c48fc9b221b98701741c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5414b97b5b7b4c7bb9df9350eb286ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f76cf591dc84f0da8383c1495421716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"naver-hyperclovax/HyperCLOVAX-SEED-Vision-Instruct-3B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=quant_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbe8b82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  k-bit 학습 준비\n",
    "base_model = prepare_model_for_kbit_training(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76b1e819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,616,768 || all params: 3,724,860,288 || trainable%: 0.0971\n"
     ]
    }
   ],
   "source": [
    "# LoRA 설정\n",
    "lora_config = LoraConfig(\n",
    "    task_type='CAUSAL_LM',\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias='none',\n",
    "    target_modules=[\"q_proj\",\"v_proj\"]\n",
    ")\n",
    "\n",
    "# LoRA 적용\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "model.enable_input_require_grads()\n",
    "model.gradient_checkpointing_enable()\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a0f08ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이징 함수\n",
    "def tokenize_function(example):\n",
    "    input_text = example[\"instruction\"] + \"\\n\" + example[\"input\"] + \"\\n\"\n",
    "    target_text = example[\"output\"]\n",
    "\n",
    "    # input_text 토크나이징\n",
    "    input_ids_only = tokenizer(input_text, truncation=True, padding=False, add_special_tokens=False)[\"input_ids\"]\n",
    "    input_len = len(input_ids_only)\n",
    "\n",
    "    # 전체 텍스트 토크나이징\n",
    "    full_text = input_text + target_text\n",
    "    tokenized = tokenizer(full_text, truncation=True, padding=\"max_length\", max_length=256)\n",
    "\n",
    "    # labels 생성, input 부분 -100 처리\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    tokenized[\"labels\"][:input_len] = [-100] * input_len\n",
    "\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57d3055f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': '다음 질문에서 법령 검색 키워드를 추출하라.', 'input': '자동차의 등화장치 색상이 규정을 어겼을 경우 어떻게 되나요?', 'output': '등화장치, 색상, 위반'}\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 로드\n",
    "dataset = load_dataset(\"json\", data_files={\n",
    "    \"train\": \"train.jsonl\",\n",
    "    \"validation\": \"valid.jsonl\"\n",
    "})\n",
    "\n",
    "print(dataset[\"train\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5da204c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15124716b1b0436583a9b2a48ec296de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1157 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4dde11f5a114b8abbad8326ad49112e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function, batched=False)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"instruction\", \"input\", \"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d051e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./hyperclovax_lora\",\n",
    "    save_strategy=\"epoch\",           # step보다 epoch 기준 체크포인트 추천\n",
    "    save_total_limit=2,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    "    report_to='none',\n",
    "    remove_unused_columns=True        # tokenized dataset 컬럼만 사용\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e3ddd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3203/4281804776.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Trainer 생성\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81ff80d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='111' max='111' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [111/111 09:25, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>86.847000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>71.263100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=111, training_loss=77.81674991642032, metrics={'train_runtime': 571.7702, 'train_samples_per_second': 6.071, 'train_steps_per_second': 0.194, 'total_flos': 1.8043149806862336e+16, 'train_loss': 77.81674991642032, 'epoch': 3.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acb581ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./hyperclovax_lora_final/tokenizer_config.json',\n",
       " './hyperclovax_lora_final/special_tokens_map.json',\n",
       " './hyperclovax_lora_final/chat_template.jinja',\n",
       " './hyperclovax_lora_final/vocab.json',\n",
       " './hyperclovax_lora_final/merges.txt',\n",
       " './hyperclovax_lora_final/added_tokens.json',\n",
       " './hyperclovax_lora_final/tokenizer.json')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./hyperclovax_lora_final\")\n",
    "tokenizer.save_pretrained(\"./hyperclovax_lora_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a48f92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0ad559ac32448e860348d717127687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_name = \"naver-hyperclovax/HyperCLOVAX-SEED-Vision-Instruct-3B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./hyperclovax_lora_final\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_name)\n",
    "model = PeftModel.from_pretrained(base_model, \"./hyperclovax_lora_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1d5b436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3d65f9d03e44ecbb659d4789960625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e5a3dc22174dc39cab4c729578e5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f87ffa3ad64f2b9585cf0e5c996db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/poketmon/hyperclovax_lora_3B/commit/abadcc89dbf5d2d592aac951b0ab8570b2ad3036', commit_message='Upload tokenizer', commit_description='', oid='abadcc89dbf5d2d592aac951b0ab8570b2ad3036', pr_url=None, repo_url=RepoUrl('https://huggingface.co/poketmon/hyperclovax_lora_3B', endpoint='https://huggingface.co', repo_type='model', repo_id='poketmon/hyperclovax_lora_3B'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hugging Face Hub에 push\n",
    "model.push_to_hub(\"poketmon/hyperclovax_lora_3B\")\n",
    "tokenizer.push_to_hub(\"poketmon/hyperclovax_lora_3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d4c344d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): HCXVisionForCausalLM(\n",
       "      (vision_model): SiglipVisionModel(\n",
       "        (vision_model): SiglipVisionTransformer(\n",
       "          (embeddings): SiglipVisionEmbeddings(\n",
       "            (patch_embedding): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14), padding=valid)\n",
       "            (position_embedding): Embedding(729, 1152)\n",
       "          )\n",
       "          (encoder): SiglipEncoder(\n",
       "            (layers): ModuleList(\n",
       "              (0-26): 27 x SiglipEncoderLayer(\n",
       "                (layer_norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "                (self_attn): SiglipAttention(\n",
       "                  (k_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                  (v_proj): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1152, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=1152, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (q_proj): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=1152, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=1152, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (out_proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "                )\n",
       "                (layer_norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "                (mlp): SiglipMLP(\n",
       "                  (activation_fn): PytorchGELUTanh()\n",
       "                  (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "                  (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (post_layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (head): SiglipMultiheadAttentionPoolingHead(\n",
       "            (attention): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=1152, out_features=1152, bias=True)\n",
       "            )\n",
       "            (layernorm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): SiglipMLP(\n",
       "              (activation_fn): PytorchGELUTanh()\n",
       "              (fc1): Linear(in_features=1152, out_features=4304, bias=True)\n",
       "              (fc2): Linear(in_features=4304, out_features=1152, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mm_projector): HCXVisionCAbstractor(\n",
       "        (net): Sequential(\n",
       "          (0): RegStage(\n",
       "            (b1): Bottleneck(\n",
       "              (conv1): ConvNormAct(\n",
       "                (conv): Conv2d(1152, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): LayerNormAct2d(\n",
       "                  (1152,), eps=1e-05, elementwise_affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (conv2): ConvNormAct(\n",
       "                (conv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "                (bn): LayerNormAct2d(\n",
       "                  (1152,), eps=1e-05, elementwise_affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (se): SEModule(\n",
       "                (fc1): Conv2d(1152, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "                (fc2): Conv2d(288, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv3): ConvNormAct(\n",
       "                (conv): Conv2d(1152, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): LayerNormAct2d(\n",
       "                  (1152,), eps=1e-05, elementwise_affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "              (act3): SiLU()\n",
       "              (downsample): Identity()\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (b2): Bottleneck(\n",
       "              (conv1): ConvNormAct(\n",
       "                (conv): Conv2d(1152, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): LayerNormAct2d(\n",
       "                  (1152,), eps=1e-05, elementwise_affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (conv2): ConvNormAct(\n",
       "                (conv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "                (bn): LayerNormAct2d(\n",
       "                  (1152,), eps=1e-05, elementwise_affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (se): SEModule(\n",
       "                (fc1): Conv2d(1152, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "                (fc2): Conv2d(288, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv3): ConvNormAct(\n",
       "                (conv): Conv2d(1152, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): LayerNormAct2d(\n",
       "                  (1152,), eps=1e-05, elementwise_affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "              (act3): SiLU()\n",
       "              (downsample): Identity()\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (b3): Bottleneck(\n",
       "              (conv1): ConvNormAct(\n",
       "                (conv): Conv2d(1152, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): LayerNormAct2d(\n",
       "                  (1152,), eps=1e-05, elementwise_affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (conv2): ConvNormAct(\n",
       "                (conv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "                (bn): LayerNormAct2d(\n",
       "                  (1152,), eps=1e-05, elementwise_affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (se): SEModule(\n",
       "                (fc1): Conv2d(1152, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "                (fc2): Conv2d(288, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv3): ConvNormAct(\n",
       "                (conv): Conv2d(1152, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): LayerNormAct2d(\n",
       "                  (1152,), eps=1e-05, elementwise_affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "              (act3): SiLU()\n",
       "              (downsample): Identity()\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "          (1): AdaptiveAvgPool2d(output_size=(9, 9))\n",
       "          (2): RegStage(\n",
       "            (b1): Bottleneck(\n",
       "              (conv1): ConvNormAct(\n",
       "                (conv): Conv2d(1152, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): LayerNormAct2d(\n",
       "                  (1152,), eps=1e-05, elementwise_affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (conv2): ConvNormAct(\n",
       "                (conv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "                (bn): LayerNormAct2d(\n",
       "                  (1152,), eps=1e-05, elementwise_affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (se): SEModule(\n",
       "                (fc1): Conv2d(1152, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "                (fc2): Conv2d(288, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv3): ConvNormAct(\n",
       "                (conv): Conv2d(1152, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): LayerNormAct2d(\n",
       "                  (1152,), eps=1e-05, elementwise_affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "              (act3): SiLU()\n",
       "              (downsample): Identity()\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (b2): Bottleneck(\n",
       "              (conv1): ConvNormAct(\n",
       "                (conv): Conv2d(1152, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): LayerNormAct2d(\n",
       "                  (1152,), eps=1e-05, elementwise_affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (conv2): ConvNormAct(\n",
       "                (conv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "                (bn): LayerNormAct2d(\n",
       "                  (1152,), eps=1e-05, elementwise_affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (se): SEModule(\n",
       "                (fc1): Conv2d(1152, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "                (fc2): Conv2d(288, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv3): ConvNormAct(\n",
       "                (conv): Conv2d(1152, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): LayerNormAct2d(\n",
       "                  (1152,), eps=1e-05, elementwise_affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "              (act3): SiLU()\n",
       "              (downsample): Identity()\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (b3): Bottleneck(\n",
       "              (conv1): ConvNormAct(\n",
       "                (conv): Conv2d(1152, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): LayerNormAct2d(\n",
       "                  (1152,), eps=1e-05, elementwise_affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (conv2): ConvNormAct(\n",
       "                (conv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "                (bn): LayerNormAct2d(\n",
       "                  (1152,), eps=1e-05, elementwise_affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (se): SEModule(\n",
       "                (fc1): Conv2d(1152, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (bn): Identity()\n",
       "                (act): SiLU(inplace=True)\n",
       "                (fc2): Conv2d(288, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (gate): Sigmoid()\n",
       "              )\n",
       "              (conv3): ConvNormAct(\n",
       "                (conv): Conv2d(1152, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): LayerNormAct2d(\n",
       "                  (1152,), eps=1e-05, elementwise_affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "              (act3): SiLU()\n",
       "              (downsample): Identity()\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (readout): Sequential(\n",
       "          (0): Linear(in_features=1152, out_features=3072, bias=True)\n",
       "          (1): SiLU()\n",
       "          (2): Linear(in_features=3072, out_features=3072, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (language_model): LlamaForCausalLM(\n",
       "        (model): LlamaModel(\n",
       "          (embed_tokens): Embedding(110592, 3072, padding_idx=100257)\n",
       "          (layers): ModuleList(\n",
       "            (0-31): 32 x LlamaDecoderLayer(\n",
       "              (self_attn): LlamaAttention(\n",
       "                (q_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=3072, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (k_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "                (v_proj): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "              )\n",
       "              (mlp): LlamaMLP(\n",
       "                (gate_proj): Linear(in_features=3072, out_features=7168, bias=False)\n",
       "                (up_proj): Linear(in_features=3072, out_features=7168, bias=False)\n",
       "                (down_proj): Linear(in_features=7168, out_features=3072, bias=False)\n",
       "                (act_fn): SiLU()\n",
       "              )\n",
       "              (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "              (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "            )\n",
       "          )\n",
       "          (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (lm_head): Linear(in_features=3072, out_features=110592, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b49416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"이륜자동차\", \"보호모\", \"단속\", \"이륜자동차\"]\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"다음 질문에서 법령 키워드만 JSON 배열 형태로 출력하라. \"\n",
    "    \"추가 설명 없이 키워드만:\\n\"\n",
    "    \"가끔 이륜자동차를 탈 때 보호모를 안 하면 단속될 수 있나요?\"\n",
    ")\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=20,   # 키워드만 나오도록 제한\n",
    "        temperature=0.0,     # deterministic\n",
    "        do_sample=False,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "raw_result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "cleaned_result = raw_result.replace(prompt, \"\")\n",
    "\n",
    "# 3️⃣ 한글 단어만 추출 (키워드)\n",
    "keywords = re.findall(r\"[가-힣]+\", cleaned_result)\n",
    "keywords = json.dumps(keywords, ensure_ascii=False)\n",
    "# 4️⃣ JSON 배열로 출력\n",
    "print(json.dumps(keywords, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36f47b3",
   "metadata": {},
   "source": [
    "# 크로마 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "259a1e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059\n"
     ]
    }
   ],
   "source": [
    "file_path = \"vector_chunks.json\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    vector_chunks = json.load(f)\n",
    "\n",
    "print(len(vector_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "34d3e586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4b484fdf554451ad71599d3c0818b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914c8c48aae5480ebf57aba069107af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e515022f964b28b5852d9db8a47ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9aa0b7d9b8486d879275bb7c495c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/807 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cd907402184642a8d15b644f9a1db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# KURE-v1 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpai-lab/KURE-v1\")\n",
    "model = AutoModel.from_pretrained(\"nlpai-lab/KURE-v1\")\n",
    "\n",
    "def get_embedding(text: str):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "    return embeddings[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88e5478a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\"./law_db\")\n",
    "\n",
    "collection = chroma_client.get_or_create_collection(name=\"laws\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "115ec1f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m vector_chunks:\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# 1) content 벡터\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mcollection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mget_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# 2) title 벡터\u001b[39;00m\n\u001b[32m     11\u001b[39m     collection.add(\n\u001b[32m     12\u001b[39m         embeddings=[get_embedding(chunk[\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33marticle_title\u001b[39m\u001b[33m\"\u001b[39m])],\n\u001b[32m     13\u001b[39m         ids=[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtitle_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m],\n\u001b[32m     14\u001b[39m         documents=[chunk[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m]],\n\u001b[32m     15\u001b[39m         metadatas=[{\u001b[33m\"\u001b[39m\u001b[33msource_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlink_to\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcontent_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m}]\n\u001b[32m     16\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/project_env/lib/python3.12/site-packages/chromadb/api/models/Collection.py:93\u001b[39m, in \u001b[36mCollection.add\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Add embeddings to the data store.\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[33;03m    ids: The ids of the embeddings you wish to add\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     81\u001b[39m \n\u001b[32m     82\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     84\u001b[39m add_request = \u001b[38;5;28mself\u001b[39m._validate_and_prepare_add_request(\n\u001b[32m     85\u001b[39m     ids=ids,\n\u001b[32m     86\u001b[39m     embeddings=embeddings,\n\u001b[32m   (...)\u001b[39m\u001b[32m     90\u001b[39m     uris=uris,\n\u001b[32m     91\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_add\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43membeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadatas\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_request\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muris\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/project_env/lib/python3.12/site-packages/chromadb/api/rust.py:421\u001b[39m, in \u001b[36mRustBindingsAPI._add\u001b[39m\u001b[34m(self, ids, collection_id, embeddings, metadatas, documents, uris, tenant, database)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_add\u001b[39m(\n\u001b[32m    401\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    409\u001b[39m     database: \u001b[38;5;28mstr\u001b[39m = DEFAULT_DATABASE,\n\u001b[32m    410\u001b[39m ) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    411\u001b[39m     \u001b[38;5;28mself\u001b[39m.product_telemetry_client.capture(\n\u001b[32m    412\u001b[39m         CollectionAddEvent(\n\u001b[32m    413\u001b[39m             collection_uuid=\u001b[38;5;28mstr\u001b[39m(collection_id),\n\u001b[32m   (...)\u001b[39m\u001b[32m    418\u001b[39m         )\n\u001b[32m    419\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbindings\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for chunk in vector_chunks:\n",
    "    # 1) content 벡터\n",
    "    collection.add(\n",
    "        embeddings=[get_embedding(chunk[\"content\"])],\n",
    "        ids=[f\"content_{chunk['id']}\"],\n",
    "        documents=[chunk[\"content\"]],\n",
    "        metadatas=[chunk[\"metadata\"]]\n",
    "    )\n",
    "\n",
    "    # 2) title 벡터\n",
    "    collection.add(\n",
    "        embeddings=[get_embedding(chunk[\"metadata\"][\"article_title\"])],\n",
    "        ids=[f\"title_{chunk['id']}\"],\n",
    "        documents=[chunk['id']],\n",
    "        metadatas=[{\"source_type\": \"title\", \"link_to\": f\"content_{chunk['id']}\"}]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_search(query_text, top_k=5, title_weight=0.7, content_weight=0.3):\n",
    "    query_embedding = get_embedding(query_text)\n",
    "    \n",
    "    # title 검색\n",
    "    title_results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_k,\n",
    "        include=[\"metadatas\", \"documents\", \"distances\"],\n",
    "        where={\"source_type\":\"title\"}\n",
    "    )\n",
    "\n",
    "    # content 검색\n",
    "    content_results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=top_k,\n",
    "        include=[\"metadatas\", \"documents\", \"distances\"],\n",
    "        where={\"source_type\":\"law\"}\n",
    "    )\n",
    "\n",
    "    combined_scores = {}\n",
    "    combined_docs = {}\n",
    "\n",
    "    # score 계산 및 title/content 합산\n",
    "    for results, weight in [(title_results, title_weight), (content_results, content_weight)]:\n",
    "        docs = results[\"documents\"][0]\n",
    "        dists = results[\"distances\"][0]\n",
    "        metas = results[\"metadatas\"][0]\n",
    "        ids = results[\"ids\"][0]\n",
    "\n",
    "        for doc, dist, meta, vid in zip(docs, dists, metas, ids):\n",
    "            similarity = 1 - dist / 2  # cosine distance → similarity\n",
    "            score = similarity * weight\n",
    "\n",
    "            if meta.get(\"source_type\") == \"title\":\n",
    "                vid = vid.replace('title_', '')\n",
    "                content_id = meta.get(\"link_to\")\n",
    "                if content_id:\n",
    "                    doc_data = collection.get(ids=[content_id])\n",
    "                    if doc_data[\"documents\"]:\n",
    "                        doc = doc_data[\"documents\"][0]\n",
    "            else:\n",
    "                vid = vid.replace('content_', '')\n",
    "\n",
    "            combined_scores[vid] = combined_scores.get(vid, 0) + score\n",
    "            combined_docs[vid] = doc\n",
    "\n",
    "    # min–max 정규화 (0~1)\n",
    "    scores = list(combined_scores.values())\n",
    "    min_s, max_s = min(scores), max(scores)\n",
    "    for vid in combined_scores:\n",
    "        combined_scores[vid] = (combined_scores[vid] - min_s) / (max_s - min_s + 1e-8)\n",
    "\n",
    "    # 정렬\n",
    "    sorted_results = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    results = [{\"Article_no\": vid, \"Score\": combined_scores[vid], \"Content\": combined_docs[vid]} \n",
    "               for vid, _ in sorted_results[:top_k]]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03be4a6c",
   "metadata": {},
   "source": [
    "# 아무튼 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca034da",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    \"다음 질문에서 법령 키워드만 JSON 배열 형태로 출력하라. \"\n",
    "    \"추가 설명 없이 키워드만:\\n\"\n",
    "    \"가끔 이륜자동차를 탈 때 보호모를 안 하면 단속될 수 있나요?\"\n",
    ")\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=20,   # 키워드만 나오도록 제한\n",
    "        temperature=0.0,     # deterministic\n",
    "        do_sample=False,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "raw_result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "cleaned_result = raw_result.replace(prompt, \"\")\n",
    "\n",
    "# 3️⃣ 한글 단어만 추출 (키워드)\n",
    "keywords = re.findall(r\"[가-힣]+\", cleaned_result)\n",
    "keywords = json.dumps(keywords, ensure_ascii=False)\n",
    "# 4️⃣ JSON 배열로 출력\n",
    "print(json.dumps(keywords, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baa44e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = json.dumps(keywords, ensure_ascii=False)\n",
    "\n",
    "for k in keywords:\n",
    "    results = hybrid_search(k)\n",
    "    for r in results:\n",
    "        print(f\"Article_no: {r['Article_no']}, Score: {r['Score']:.4f}\")\n",
    "        print(f\"Content: {r['Content']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
